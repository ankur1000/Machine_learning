{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv('./dataset/housing.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>-124.3500</td>\n",
       "      <td>-121.8000</td>\n",
       "      <td>-118.4900</td>\n",
       "      <td>-118.01000</td>\n",
       "      <td>-114.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>32.5400</td>\n",
       "      <td>33.9300</td>\n",
       "      <td>34.2600</td>\n",
       "      <td>37.71000</td>\n",
       "      <td>41.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>20433.0</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>296.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count           mean            std         min  \\\n",
       "longitude           20640.0    -119.569704       2.003532   -124.3500   \n",
       "latitude            20640.0      35.631861       2.135952     32.5400   \n",
       "housing_median_age  20640.0      28.639486      12.585558      1.0000   \n",
       "total_rooms         20640.0    2635.763081    2181.615252      2.0000   \n",
       "total_bedrooms      20433.0     537.870553     421.385070      1.0000   \n",
       "population          20640.0    1425.476744    1132.462122      3.0000   \n",
       "households          20640.0     499.539680     382.329753      1.0000   \n",
       "median_income       20640.0       3.870671       1.899822      0.4999   \n",
       "median_house_value  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                            25%          50%           75%          max  \n",
       "longitude             -121.8000    -118.4900    -118.01000    -114.3100  \n",
       "latitude                33.9300      34.2600      37.71000      41.9500  \n",
       "housing_median_age      18.0000      29.0000      37.00000      52.0000  \n",
       "total_rooms           1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "total_bedrooms         296.0000     435.0000     647.00000    6445.0000  \n",
       "population             787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households             280.0000     409.0000     605.00000    6082.0000  \n",
       "median_income            2.5634       3.5348       4.74325      15.0001  \n",
       "median_house_value  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['total_bedrooms'] = housing['total_bedrooms'].fillna(housing['total_bedrooms'].mean())\n",
    "housing = housing.drop(columns=['longitude','latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = housing[['housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income']]\n",
    "y_data = housing['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 6)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 6761,  3010,  7812,  8480,  1051, 16312,  2042,  1755, 16022,\n",
       "            20441,\n",
       "            ...\n",
       "             2623, 17357, 20463, 12363, 16983,  5695,  8006, 17745, 17931,\n",
       "            13151],\n",
       "           dtype='int64', length=14448)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_data,test_size=0.3, random_state = 101)\n",
    "index_x_train = X_train.index\n",
    "index_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Feature Data\n",
    "### Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(copy=True, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_train.index = index_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "#### Create the necessary tf.feature_column objects for the estimator. They should all be treated as continuous numeric_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housing_median_age', 'total_rooms', 'total_bedrooms', 'population',\n",
       "       'households', 'median_income', 'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['housing_median_age' 'total_rooms' 'total_bedrooms' 'population'\n",
      " 'households' 'median_income' 'median_house_value']\n",
      "(14448,)\n"
     ]
    }
   ],
   "source": [
    "print(housing.columns.values[:-1])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='housing_median_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='total_rooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='total_bedrooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='population', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='households', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column(x) for x in housing.columns.values[:-2] ]\n",
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input function for the estimator object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=10, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the estimator model. Use a DNNRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp078y7zp3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp078y7zp3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f149f8e78d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNRegressor(hidden_units=[10,10,10],feature_columns=feat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f149f8b0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f149f8b0390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f149f8b0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f149f8b0390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f149f8b0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f149f8b0748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f149f8b0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f149f8b0748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8b0e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8bc198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8bc198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8bc198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f149f8bc198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/quantiphi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /home/quantiphi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/quantiphi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp078y7zp3/model.ckpt.\n",
      "INFO:tensorflow:loss = 419152700000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 353.407\n",
      "INFO:tensorflow:loss = 485090100000.0, step = 101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.8\n",
      "INFO:tensorflow:loss = 620695200000.0, step = 201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.509\n",
      "INFO:tensorflow:loss = 277410550000.0, step = 301 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.759\n",
      "INFO:tensorflow:loss = 466465460000.0, step = 401 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.593\n",
      "INFO:tensorflow:loss = 180646610000.0, step = 501 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.602\n",
      "INFO:tensorflow:loss = 243747100000.0, step = 601 (0.225 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 661.593\n",
      "INFO:tensorflow:loss = 82487410000.0, step = 701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.828\n",
      "INFO:tensorflow:loss = 55672270000.0, step = 801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.202\n",
      "INFO:tensorflow:loss = 21186673000.0, step = 901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.398\n",
      "INFO:tensorflow:loss = 49324397000.0, step = 1001 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.626\n",
      "INFO:tensorflow:loss = 115263550000.0, step = 1101 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.322\n",
      "INFO:tensorflow:loss = 60715786000.0, step = 1201 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.663\n",
      "INFO:tensorflow:loss = 65431460000.0, step = 1301 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.37\n",
      "INFO:tensorflow:loss = 102335580000.0, step = 1401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 736.645\n",
      "INFO:tensorflow:loss = 100628220000.0, step = 1501 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.982\n",
      "INFO:tensorflow:loss = 143335150000.0, step = 1601 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 744.056\n",
      "INFO:tensorflow:loss = 124644930000.0, step = 1701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.63\n",
      "INFO:tensorflow:loss = 67683870000.0, step = 1801 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.378\n",
      "INFO:tensorflow:loss = 42736290000.0, step = 1901 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.864\n",
      "INFO:tensorflow:loss = 121778370000.0, step = 2001 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.998\n",
      "INFO:tensorflow:loss = 82399920000.0, step = 2101 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.004\n",
      "INFO:tensorflow:loss = 70141170000.0, step = 2201 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.754\n",
      "INFO:tensorflow:loss = 76445100000.0, step = 2301 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.757\n",
      "INFO:tensorflow:loss = 97015330000.0, step = 2401 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.248\n",
      "INFO:tensorflow:loss = 198197920000.0, step = 2501 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.846\n",
      "INFO:tensorflow:loss = 272966780000.0, step = 2601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.037\n",
      "INFO:tensorflow:loss = 154473780000.0, step = 2701 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.014\n",
      "INFO:tensorflow:loss = 89592460000.0, step = 2801 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.659\n",
      "INFO:tensorflow:loss = 95849950000.0, step = 2901 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.102\n",
      "INFO:tensorflow:loss = 31999520000.0, step = 3001 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.627\n",
      "INFO:tensorflow:loss = 44012000000.0, step = 3101 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.587\n",
      "INFO:tensorflow:loss = 186170950000.0, step = 3201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.486\n",
      "INFO:tensorflow:loss = 114673770000.0, step = 3301 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.777\n",
      "INFO:tensorflow:loss = 55754220000.0, step = 3401 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.339\n",
      "INFO:tensorflow:loss = 135096680000.0, step = 3501 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.745\n",
      "INFO:tensorflow:loss = 109680920000.0, step = 3601 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.222\n",
      "INFO:tensorflow:loss = 191068730000.0, step = 3701 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.844\n",
      "INFO:tensorflow:loss = 125868450000.0, step = 3801 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.004\n",
      "INFO:tensorflow:loss = 73237610000.0, step = 3901 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.634\n",
      "INFO:tensorflow:loss = 117596190000.0, step = 4001 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.748\n",
      "INFO:tensorflow:loss = 105664000000.0, step = 4101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.099\n",
      "INFO:tensorflow:loss = 47843185000.0, step = 4201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.243\n",
      "INFO:tensorflow:loss = 149876540000.0, step = 4301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.229\n",
      "INFO:tensorflow:loss = 72149550000.0, step = 4401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.342\n",
      "INFO:tensorflow:loss = 109920354000.0, step = 4501 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.174\n",
      "INFO:tensorflow:loss = 50380198000.0, step = 4601 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.866\n",
      "INFO:tensorflow:loss = 189108040000.0, step = 4701 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 744.287\n",
      "INFO:tensorflow:loss = 85621730000.0, step = 4801 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.504\n",
      "INFO:tensorflow:loss = 89891660000.0, step = 4901 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.707\n",
      "INFO:tensorflow:loss = 86141620000.0, step = 5001 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.403\n",
      "INFO:tensorflow:loss = 47478100000.0, step = 5101 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.127\n",
      "INFO:tensorflow:loss = 37591400000.0, step = 5201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.089\n",
      "INFO:tensorflow:loss = 57995325000.0, step = 5301 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.669\n",
      "INFO:tensorflow:loss = 135125270000.0, step = 5401 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.553\n",
      "INFO:tensorflow:loss = 49758593000.0, step = 5501 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.765\n",
      "INFO:tensorflow:loss = 36313813000.0, step = 5601 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.476\n",
      "INFO:tensorflow:loss = 68687810000.0, step = 5701 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.474\n",
      "INFO:tensorflow:loss = 36387463000.0, step = 5801 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.33\n",
      "INFO:tensorflow:loss = 95618470000.0, step = 5901 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.915\n",
      "INFO:tensorflow:loss = 23418872000.0, step = 6001 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.059\n",
      "INFO:tensorflow:loss = 71187120000.0, step = 6101 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.295\n",
      "INFO:tensorflow:loss = 82322350000.0, step = 6201 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.015\n",
      "INFO:tensorflow:loss = 143609410000.0, step = 6301 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.055\n",
      "INFO:tensorflow:loss = 49280307000.0, step = 6401 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.666\n",
      "INFO:tensorflow:loss = 122279920000.0, step = 6501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.862\n",
      "INFO:tensorflow:loss = 193917530000.0, step = 6601 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.866\n",
      "INFO:tensorflow:loss = 25474904000.0, step = 6701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.027\n",
      "INFO:tensorflow:loss = 260089100000.0, step = 6801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.957\n",
      "INFO:tensorflow:loss = 78705910000.0, step = 6901 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.901\n",
      "INFO:tensorflow:loss = 76930240000.0, step = 7001 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.269\n",
      "INFO:tensorflow:loss = 116585120000.0, step = 7101 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.17\n",
      "INFO:tensorflow:loss = 117385590000.0, step = 7201 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.18\n",
      "INFO:tensorflow:loss = 55546860000.0, step = 7301 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.377\n",
      "INFO:tensorflow:loss = 54636642000.0, step = 7401 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.997\n",
      "INFO:tensorflow:loss = 130626175000.0, step = 7501 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.973\n",
      "INFO:tensorflow:loss = 66128495000.0, step = 7601 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.248\n",
      "INFO:tensorflow:loss = 151972600000.0, step = 7701 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.249\n",
      "INFO:tensorflow:loss = 111472430000.0, step = 7801 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.186\n",
      "INFO:tensorflow:loss = 96441115000.0, step = 7901 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.052\n",
      "INFO:tensorflow:loss = 89171080000.0, step = 8001 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.952\n",
      "INFO:tensorflow:loss = 66801760000.0, step = 8101 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.8\n",
      "INFO:tensorflow:loss = 135011795000.0, step = 8201 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.415\n",
      "INFO:tensorflow:loss = 95309980000.0, step = 8301 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.178\n",
      "INFO:tensorflow:loss = 102243530000.0, step = 8401 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.368\n",
      "INFO:tensorflow:loss = 97751320000.0, step = 8501 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 59000340000.0, step = 8601 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.034\n",
      "INFO:tensorflow:loss = 189052860000.0, step = 8701 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 728.798\n",
      "INFO:tensorflow:loss = 145297870000.0, step = 8801 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.826\n",
      "INFO:tensorflow:loss = 142236700000.0, step = 8901 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.394\n",
      "INFO:tensorflow:loss = 53962170000.0, step = 9001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.214\n",
      "INFO:tensorflow:loss = 274242010000.0, step = 9101 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.751\n",
      "INFO:tensorflow:loss = 91240890000.0, step = 9201 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.191\n",
      "INFO:tensorflow:loss = 63345910000.0, step = 9301 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.363\n",
      "INFO:tensorflow:loss = 40517358000.0, step = 9401 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.657\n",
      "INFO:tensorflow:loss = 133383770000.0, step = 9501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.513\n",
      "INFO:tensorflow:loss = 54283770000.0, step = 9601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.448\n",
      "INFO:tensorflow:loss = 106465150000.0, step = 9701 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 728.208\n",
      "INFO:tensorflow:loss = 84706705000.0, step = 9801 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.568\n",
      "INFO:tensorflow:loss = 69144710000.0, step = 9901 (0.135 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp078y7zp3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 63754170000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7f149f8e7780>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dnn_model.predict(pred_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f148e5c97f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f148e5c97f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f148e5c97f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f148e5c97f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f148e5e9208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f148e5e9208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f148e5e9208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f148e5e9208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e98d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e98d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e98d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e98d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f148e5e9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/quantiphi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp078y7zp3/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = [pred['predictions'] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99363.23782463209"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
